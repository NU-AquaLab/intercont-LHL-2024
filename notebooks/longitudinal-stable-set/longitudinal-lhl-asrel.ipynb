{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "import rootpath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import geopandas as gpd\n",
    "import pycountry as pc\n",
    "import pycountry_convert as pcc\n",
    "import powerlaw\n",
    "from matplotlib.patches import Circle\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from lhledge import cfgLoader\n",
    "from lhledge import lhlFilters\n",
    "from lhledge import loadGeographicData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYCLE = 8820\n",
    "DATE = 20201002\n",
    "# CYCLE = 4578\n",
    "# DATE = 20160302\n",
    "DOWNSAMPLING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unfold_prefix(prefix):\n",
    "    net, mask = prefix.split(\"/\")\n",
    "\n",
    "    o0, o1, o2, o3 = np.array(net.split(\".\")).astype(int)\n",
    "\n",
    "    if int(mask) == 24:\n",
    "        # return net\n",
    "        return [net,]\n",
    "    elif int(mask) < 24:\n",
    "        p = []\n",
    "        for i in range(24 - int(mask)):\n",
    "            p.append(f\"{o0}.{o1}.{o2+ i}.{o3}\")\n",
    "        return p\n",
    "    else:\n",
    "        return [net,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def toslash24(prefix):\n",
    "\n",
    "    o0, o1, o2, o3 = np.array(prefix.split(\".\")).astype(int)\n",
    "\n",
    "    return f\"{o0}.{o1}.{o2}.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ecdf(data, w=[]):\n",
    "    \"\"\" Compute ECDF \"\"\"\n",
    "    if len(w) == 0:\n",
    "        w = np.ones(len(data))\n",
    "    #\n",
    "    #     x = np.sort(data)\n",
    "    idx = np.argsort(data)\n",
    "    #\n",
    "    x = np.array(data)\n",
    "    x = x[idx]\n",
    "    w = w[idx]\n",
    "    #\n",
    "    n = x.size\n",
    "    #     y = np.arange(1, n + 1) / n\n",
    "    y = np.cumsum(w) / sum(w)\n",
    "    return (np.squeeze(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def geneate_input_filename(date, cycle):\n",
    "\n",
    "    filename = cfg[\"paths\"][\"ark\"][\"consolidated-stable-long-haul-explorations\"].format(date, cycle, DOWNSAMPLING)\n",
    "\n",
    "    # filenames._create_dir(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Change directory to run from the root dir of the project\n",
    "path = rootpath.detect(pattern=\".git\")\n",
    "os.chdir(path)\n",
    "\n",
    "# load config file\n",
    "cfg = cfgLoader.cfgLoader(\"config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_continent(cc):\n",
    "    if cc == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        country = pc.countries.get(alpha_2=cc)\n",
    "        continent = pcc.country_alpha2_to_continent_code(country.alpha_2)\n",
    "        return continent\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_with_cepii(cepii, geoloc_hops):\n",
    "\n",
    "    # agrego CEPII y elimino cortos\n",
    "\n",
    "    SoL_TH = 100\n",
    "    geoloc_hops[\"near_side_cont\"] = geoloc_hops[\"near_side_cc\"].map(_get_continent)\n",
    "    geoloc_hops[\"far_side_cont\"] = geoloc_hops[\"far_side_cc\"].map(_get_continent)\n",
    "\n",
    "    tmp = geoloc_hops.loc[(geoloc_hops[\"diff_rtt\"] > 57) \\\n",
    "                    & (geoloc_hops[\"near_side_cont\"]\n",
    "                       != geoloc_hops[\"far_side_cont\"])] \\\n",
    "            [[\"near_side_addr\", \"far_side_addr\",\n",
    "              \"near_side_cc\", \"far_side_cc\",\n",
    "              \"near_node_id\", \"far_node_id\",\n",
    "              \"near_node_asn\", \"far_node_asn\",\n",
    "              \"near_side_lat\", \"far_side_lat\",\n",
    "              \"near_side_lon\", \"far_side_lon\",\n",
    "              \"diff_rtt\"]]\n",
    "\n",
    "    tmp = tmp.groupby([\"near_side_cc\", \"far_side_cc\",\n",
    "                       \"near_side_addr\", \"far_side_addr\",\n",
    "                       \"near_node_id\", \"far_node_id\",\n",
    "                       \"near_side_lat\", \"far_side_lat\",\n",
    "                       \"near_side_lon\", \"far_side_lon\",\n",
    "                       \"near_node_asn\", \"far_node_asn\",]) \\\n",
    "        .min()[\"diff_rtt\"] \\\n",
    "        .reset_index()\n",
    "\n",
    "    tmp = tmp.join(\n",
    "        cepii[[\"cc_src\", \"cc_dst\", \"dist\"]].set_index([\"cc_src\", \"cc_dst\"]),\n",
    "        on=[\"near_side_cc\", \"far_side_cc\"],\n",
    "        how='left',\n",
    "        lsuffix='_left',\n",
    "        rsuffix='_right'\n",
    "    )\n",
    "\n",
    "    # Cond 1: no violation of speed of light contrains\n",
    "    # Cond 2: No long detours. Latency can't be twice the inter-country distance\n",
    "    tmp = tmp.loc[(tmp[\"diff_rtt\"] > (tmp[\"dist\"] / SoL_TH))\n",
    "                   & ((tmp[\"diff_rtt\"]  * SoL_TH) < (2 * tmp[\"dist\"]))]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ixp_flag(x):\n",
    "    if len(x) == 0:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def add_ixp_data(lhl, ixps_nets):\n",
    "\n",
    "\n",
    "    lhl[\"near_prefix\"] =  lhl[\"near_side_addr\"].map(toslash24)\n",
    "    lhl[\"far_prefix\"] =  lhl[\"far_side_addr\"].map(toslash24)\n",
    "\n",
    "    lhl = lhl.join(\n",
    "        ixps_nets.set_index([\"net\", ]),\n",
    "        on=[\"near_prefix\", ],\n",
    "        how='left',\n",
    "        lsuffix='_left',\n",
    "        rsuffix='_near'\n",
    "    )\n",
    "    lhl = lhl.rename(columns = {'ixp': 'near_side_ixp'})\n",
    "\n",
    "    lhl = lhl.join(\n",
    "        ixps_nets.set_index([\"net\", ]),\n",
    "        on=[\"far_prefix\", ],\n",
    "        how='left',\n",
    "        lsuffix='_left',\n",
    "        rsuffix='_far'\n",
    "    )\n",
    "    lhl = lhl.rename(columns = {'ixp': 'far_side_ixp'})\n",
    "\n",
    "    lhl['near_side_ixp'] = lhl['near_side_ixp'].fillna(\"\")\n",
    "    lhl['far_side_ixp'] = lhl['far_side_ixp'].fillna(\"\")\n",
    "\n",
    "    lhl[\"flag_near_side_ixp\"] = lhl[\"near_side_ixp\"].map(ixp_flag)\n",
    "    lhl[\"flag_far_side_ixp\"] = lhl[\"far_side_ixp\"].map(ixp_flag)\n",
    "\n",
    "    return lhl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IXP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/raw/ixps/ixs_202110.json\") as json_file:\n",
    "    ixps = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ixp</th>\n",
       "      <th>net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-IX Internet Exchange</td>\n",
       "      <td>185.1.213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36C3-YOLOIXP</td>\n",
       "      <td>185.236.243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48 IX</td>\n",
       "      <td>149.112.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b42 Internet Exchange Point</td>\n",
       "      <td>185.1.125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6NGIX</td>\n",
       "      <td>203.254.32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ixp            net\n",
       "0        1-IX Internet Exchange    185.1.213.0\n",
       "1                  36C3-YOLOIXP  185.236.243.0\n",
       "2                         48 IX    149.112.3.0\n",
       "3  4b42 Internet Exchange Point    185.1.125.0\n",
       "4                         6NGIX   203.254.32.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ixps_nets = []\n",
    "\n",
    "for ixp in ixps:\n",
    "    for prefix in ixp[\"prefixes\"][\"ipv4\"]:\n",
    "        for slash24 in unfold_prefix(prefix):\n",
    "            ixps_nets.append((ixp[\"name\"], slash24))\n",
    "\n",
    "ixps_nets = pd.DataFrame(ixps_nets, columns=[\"ixp\", \"net\"])\n",
    "ixps_nets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_src</th>\n",
       "      <th>cc_dst</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AW</td>\n",
       "      <td>AW</td>\n",
       "      <td>5.225315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AW</td>\n",
       "      <td>AF</td>\n",
       "      <td>13257.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AW</td>\n",
       "      <td>AO</td>\n",
       "      <td>9516.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AW</td>\n",
       "      <td>AI</td>\n",
       "      <td>983.268200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AW</td>\n",
       "      <td>AL</td>\n",
       "      <td>9091.742000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cc_src cc_dst          dist\n",
       "0     AW     AW      5.225315\n",
       "1     AW     AF  13257.810000\n",
       "2     AW     AO   9516.913000\n",
       "3     AW     AI    983.268200\n",
       "4     AW     AL   9091.742000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepii = loadGeographicData.load_inter_country_distances(\"data/external/cepii/dist_cepii.csv\", \n",
    "                                     \"data/processed/min-cc-dist/min_cc_dist.csv\")\n",
    "cepii.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LHLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_geoloc_hops = {}\n",
    "\n",
    "for date, cycle in [(20220501, 10019), (20220501, 10020), (20220502, 10021),\n",
    "                    (20211001, 9643), (20211001, 9644), (20211002, 9645),\n",
    "                    (20201009, 8838), (20201009, 8839), (20201009, 8840),\n",
    "                    (20201002, 8820), (20201002, 8821), (20201002, 8822),\n",
    "                    (20160302, 4576), (20160302, 4577), (20160302, 4578),\n",
    "                    (20190801, 7615), (20190801, 7616), (20190801, 7617),\n",
    "                    (20180301, 6446), (20180301, 6447), (20180301, 6448),\n",
    "                    (20170201, 5422), (20170201, 5423), (20170201, 5424),]:   \n",
    "\n",
    "    lhl = pd.read_csv(geneate_input_filename(date, cycle),\n",
    "                               compression=\"bz2\")\n",
    "    lhl[\"mpls_tunnel\"] = lhl[\"mpls_tunnel\"].astype(bool)\n",
    "\n",
    "    _geoloc_hops = lhl.drop_duplicates([\"near_side_addr\", \"far_side_addr\"]) \\\n",
    "                      .loc[(lhl[\"near_side_cc\"] != \"??\")\n",
    "                           & (lhl[\"far_side_cc\"] != \"??\")\n",
    "                           & (lhl[\"far_side_rtt\"] >  lhl[\"near_side_rtt\"])] \\\n",
    "                      [[\"near_side_addr\", \"far_side_addr\",\n",
    "                        \"near_node_id\", \"far_node_id\",\n",
    "                        \"near_side_cc\", \"far_side_cc\",\n",
    "                        \"near_side_lat\", \"far_side_lat\",\n",
    "                        \"near_side_lon\", \"far_side_lon\",\n",
    "                        \"near_node_asn\", \"far_node_asn\",]]\n",
    "\n",
    "    min_near = lhl.groupby([\"near_side_addr\", \"far_side_addr\"])[\"near_side_rtt\"] \\\n",
    "        .min() \\\n",
    "        .reset_index()\n",
    "\n",
    "    min_far = lhl.groupby([\"near_side_addr\", \"far_side_addr\"])[\"far_side_rtt\"] \\\n",
    "        .min() \\\n",
    "        .reset_index()\n",
    "\n",
    "\n",
    "    _geoloc_hops = _geoloc_hops.join(\n",
    "            min_near.set_index([\"near_side_addr\", \"far_side_addr\"]),\n",
    "            on=[\"near_side_addr\", \"far_side_addr\"],\n",
    "            how='left',\n",
    "            lsuffix='_left',\n",
    "            rsuffix='_right'\n",
    "        )\n",
    "\n",
    "    _geoloc_hops = _geoloc_hops.join(\n",
    "            min_far.set_index([\"near_side_addr\", \"far_side_addr\"]),\n",
    "            on=[\"near_side_addr\", \"far_side_addr\"],\n",
    "            how='left',\n",
    "            lsuffix='_left',\n",
    "            rsuffix='_right'\n",
    "        )\n",
    "\n",
    "\n",
    "    _geoloc_hops[\"diff_rtt\"] = _geoloc_hops[\"far_side_rtt\"] - _geoloc_hops[\"near_side_rtt\"]\n",
    "\n",
    "    _geoloc_hops = _geoloc_hops.loc[(_geoloc_hops[\"near_side_cc\"].notnull())\n",
    "                                    & (_geoloc_hops[\"far_side_cc\"].notnull())]\n",
    "\n",
    "\n",
    "    filtered_geoloc_hops[cycle] = filter_with_cepii(cepii, _geoloc_hops)\n",
    "    filtered_geoloc_hops[cycle] = add_ixp_data(filtered_geoloc_hops[cycle], ixps_nets)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577\t10202\t858\t1714\t661\t17\t13452\t0.76\t0.06\t0.13\t0.05\n",
      "5423\t12346\t624\t2012\t1190\t40\t16212\t0.76\t0.04\t0.12\t0.07\n",
      "6447\t14172\t864\t2312\t1192\t0\t18540\t0.76\t0.05\t0.12\t0.06\n",
      "7616\t24812\t1622\t3588\t1276\t224\t31522\t0.79\t0.05\t0.11\t0.04\n",
      "8821\t29264\t718\t2556\t740\t2\t33280\t0.88\t0.02\t0.08\t0.02\n",
      "9644\t41354\t1278\t6138\t1532\t2\t50304\t0.82\t0.03\t0.12\t0.03\n",
      "10020\t36796\t870\t5140\t1694\t0\t44500\t0.83\t0.02\t0.12\t0.04\n"
     ]
    }
   ],
   "source": [
    "asrel_mapping ={\n",
    "    4577: 20160301,\n",
    "    5423: 20170201,\n",
    "    6447: 20180401,\n",
    "    7616: 20190801,\n",
    "    8821: 20201001,\n",
    "    9644: 20211001,\n",
    "    10020: 20220501\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# for cycle in [4577, 5423, 6447, 7616, 8821, 8839]:\n",
    "for cycle in [4577, 5423, 6447, 7616, 8821, 9644, 10020]:\n",
    "    concat_df = pd.DataFrame()\n",
    "    for _cycle in range(cycle -1, cycle + 2):\n",
    "        concat_df = pd.concat([concat_df, filtered_geoloc_hops[_cycle]])\n",
    "\n",
    "    G = nx.from_pandas_edgelist(\n",
    "        concat_df.loc[concat_df[\"diff_rtt\"] > 40],\n",
    "        \"near_node_id\",\n",
    "        \"far_node_id\",\n",
    "    )\n",
    "\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"near_node_asn\"].values,\n",
    "            index=concat_df[\"near_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'asn',\n",
    "    )\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"far_node_asn\"].values,\n",
    "            index=concat_df[\"far_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'asn',\n",
    "    )\n",
    "\n",
    "    asrel = pd.read_csv(\n",
    "        f\"data/raw/asrel/{asrel_mapping[cycle]}.as-rel.txt.bz2\",\n",
    "        compression=\"bz2\",\n",
    "        sep=\"|\",\n",
    "        comment=\"#\",\n",
    "        names=[\"provider\", \"customer\", \"type\"]\n",
    "    )\n",
    "\n",
    "    t = len(G.edges())\n",
    "\n",
    "    i = 0\n",
    "    p2p = 0\n",
    "    p2c = 0\n",
    "    tor_uknown = 0\n",
    "    unmapped = 0\n",
    "\n",
    "    for node in G.nodes():\n",
    "        for neighbor_id in G.neighbors(node):\n",
    "\n",
    "            near_asn = int(G.nodes[node][\"asn\"])\n",
    "            far_asn = int(G.nodes[neighbor_id][\"asn\"])\n",
    "\n",
    "            if (near_asn != 0) and (near_asn != 0):\n",
    "                if near_asn == far_asn:\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tor = asrel.loc[\n",
    "                        ((asrel[\"provider\"] == near_asn)\n",
    "                         & (asrel[\"customer\"] == far_asn))\n",
    "                        | ((asrel[\"customer\"] == near_asn)\n",
    "                           & (asrel[\"provider\"] == far_asn))\n",
    "                    ][\"type\"].values\n",
    "\n",
    "                    if len(tor) > 0:\n",
    "                        tor = tor[0]\n",
    "                    else:\n",
    "                        tor = 1\n",
    "\n",
    "                    if tor == -1:\n",
    "                        p2c +=1\n",
    "                    elif tor == 0:\n",
    "                        p2p += 1\n",
    "                    else:\n",
    "                        tor_uknown += 1\n",
    "            else:\n",
    "                unmapped += 1\n",
    "    t *= 2\n",
    "    print(f\"{cycle}\\t{i}\\t{p2p}\\t{p2c}\\t{tor_uknown}\\t{unmapped}\\t{t}\\t{(i / float(t)):.02f}\\t{(p2p / float(t)):.02f}\\t{(p2c / float(t)):.02f}\\t{(tor_uknown / float(t)):.02f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22250"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cycle in [10020, ]:\n",
    "    concat_df = pd.DataFrame()\n",
    "    for _cycle in range(cycle -1, cycle + 2):\n",
    "        # concat_df = concat_df.append(filtered_geoloc_hops[_cycle])\n",
    "        concat_df = pd.concat([concat_df, filtered_geoloc_hops[_cycle]])\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    concat_df.loc[concat_df[\"diff_rtt\"] > 40],\n",
    "    \"near_node_id\",\n",
    "    \"far_node_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46224, 20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577    &5101.0 (0.76)    &461.0 (0.07)    &893.0 (0.13)    &131 (0.02)    &197.0 (0.03)    &17 (0.00)    &6726\n",
      "5423    &6173.0 (0.76)    &494.0 (0.06)    &1044.0 (0.13)    &130 (0.02)    &310.0 (0.04)    &40 (0.00)    &8106\n",
      "6447    &7086.0 (0.76)    &602.0 (0.06)    &1286.0 (0.14)    &170 (0.02)    &211.0 (0.02)    &0 (0.00)    &9270\n",
      "7616    &12406.0 (0.79)    &873.0 (0.06)    &1873.0 (0.12)    &187 (0.01)    &403.5 (0.03)    &224 (0.01)    &15761\n",
      "8821    &14632.0 (0.88)    &465.0 (0.03)    &1285.0 (0.08)    &90 (0.01)    &212.0 (0.01)    &2 (0.00)    &16640\n",
      "9644    &20677.0 (0.82)    &915.0 (0.04)    &2961.0 (0.12)    &100 (0.00)    &548.0 (0.02)    &2 (0.00)    &25152\n",
      "10020    &18398.0 (0.83)    &652.0 (0.03)    &2510.0 (0.11)    &106 (0.00)    &637.0 (0.03)    &0 (0.00)    &22250\n"
     ]
    }
   ],
   "source": [
    "asrel_mapping ={\n",
    "    4577: 20160301,\n",
    "    5423: 20170201,\n",
    "    6447: 20180401,\n",
    "    7616: 20190801,\n",
    "    8821: 20201001,\n",
    "    9644: 20211001,\n",
    "    10020: 20220501\n",
    "}\n",
    "\n",
    "asrel = pd.DataFrame()\n",
    "\n",
    "for cycle in asrel_mapping.keys():\n",
    "    _asrel = pd.read_csv(\n",
    "        f\"data/raw/asrel/{asrel_mapping[cycle]}.as-rel.txt.bz2\",\n",
    "        compression=\"bz2\",\n",
    "        sep=\"|\",\n",
    "        comment=\"#\",\n",
    "        names=[\"provider\", \"customer\", \"type\"]\n",
    "    )\n",
    "    # asrel = asrel.append(_asrel)\n",
    "    asrel = pd.concat([asrel, _asrel])\n",
    "\n",
    "\n",
    "for cycle in [4577, 5423, 6447, 7616, 8821, 9644, 10020]:\n",
    "    concat_df = pd.DataFrame()\n",
    "    for _cycle in range(cycle -1, cycle + 2):\n",
    "        # concat_df = concat_df.append(filtered_geoloc_hops[_cycle])\n",
    "        concat_df = pd.concat([concat_df, filtered_geoloc_hops[_cycle]])\n",
    "\n",
    "    G = nx.from_pandas_edgelist(\n",
    "        concat_df.loc[concat_df[\"diff_rtt\"] > 40],\n",
    "        \"near_node_id\",\n",
    "        \"far_node_id\",\n",
    "    )\n",
    "\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"near_node_asn\"].values,\n",
    "            index=concat_df[\"near_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'asn',\n",
    "    )\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"far_node_asn\"].values,\n",
    "            index=concat_df[\"far_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'asn',\n",
    "    )\n",
    "\n",
    "\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"flag_far_side_ixp\"].values,\n",
    "            index=concat_df[\"near_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'ixp_flag',\n",
    "    )\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"flag_near_side_ixp\"].values,\n",
    "            index=concat_df[\"far_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'ixp_flag',\n",
    "    )\n",
    "\n",
    "    t = len(G.edges())\n",
    "\n",
    "    i = 0\n",
    "    p2p = 0\n",
    "    p2c = 0\n",
    "    ixp = 0\n",
    "    tor_uknown = 0\n",
    "    unmapped = 0\n",
    "\n",
    "    for node in G.nodes():\n",
    "        for neighbor_id in G.neighbors(node):\n",
    "\n",
    "            near_asn = int(G.nodes[node][\"asn\"])\n",
    "            far_asn = int(G.nodes[neighbor_id][\"asn\"])\n",
    "\n",
    "            if (near_asn != 0) and (near_asn != 0):\n",
    "                if near_asn == far_asn:\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tor = asrel.loc[\n",
    "                        ((asrel[\"provider\"] == near_asn)\n",
    "                         & (asrel[\"customer\"] == far_asn))\n",
    "                        | ((asrel[\"customer\"] == near_asn)\n",
    "                           & (asrel[\"provider\"] == far_asn))\n",
    "                    ][\"type\"].values\n",
    "\n",
    "                    if len(tor) > 0:\n",
    "                        tor = tor[0]\n",
    "                    else:\n",
    "                        tor = 1\n",
    "\n",
    "                    if tor == -1:\n",
    "                        p2c +=1\n",
    "                    elif tor == 0:\n",
    "                        p2p += 1\n",
    "                    else:\n",
    "                        if G.nodes[node][\"ixp_flag\"] or G.nodes[neighbor_id][\"ixp_flag\"]:\n",
    "                            ixp +=1\n",
    "                        else:\n",
    "                            tor_uknown += 1\n",
    "            else:\n",
    "                unmapped += 1\n",
    "    i /= 2\n",
    "    p2p /= 2\n",
    "    p2c /= 2\n",
    "    tor_uknown /= 2\n",
    "\n",
    "    print(f\"{cycle}\\\n",
    "    &{i} ({(i / float(t)):.02f})\\\n",
    "    &{p2p} ({(p2p / float(t)):.02f})\\\n",
    "    &{p2c} ({(p2c / float(t)):.02f})\\\n",
    "    &{ixp} ({(ixp / float(t)):.02f})\\\n",
    "    &{tor_uknown} ({(tor_uknown / float(t)):.02f})\\\n",
    "    &{unmapped} ({(unmapped / float(t)):.02f})\\\n",
    "    &{t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "asrel_mapping ={\n",
    "    4577: 20160301,\n",
    "    5423: 20170201,\n",
    "    6447: 20180401,\n",
    "    7616: 20190801,\n",
    "    8821: 20201001,\n",
    "    9644: 20211001,\n",
    "    10020: 20220501\n",
    "}\n",
    "\n",
    "asrel = pd.DataFrame()\n",
    "\n",
    "for cycle in asrel_mapping.keys():\n",
    "    _asrel = pd.read_csv(\n",
    "        f\"data/raw/asrel/{asrel_mapping[cycle]}.as-rel.txt.bz2\",\n",
    "        compression=\"bz2\",\n",
    "        sep=\"|\",\n",
    "        comment=\"#\",\n",
    "        names=[\"provider\", \"customer\", \"type\"]\n",
    "    )\n",
    "    # asrel = asrel.append(_asrel)\n",
    "    asrel = pd.concat([asrel, _asrel])\n",
    "    \n",
    "\n",
    "\n",
    "t1 = []\n",
    "t2 = []\n",
    "for cycle in [4577, 5423, 6447, 7616, 8821, 9644, 10020]:\n",
    "    concat_df = pd.DataFrame()\n",
    "    for _cycle in range(cycle -1, cycle + 2):\n",
    "        # concat_df = concat_df.append(filtered_geoloc_hops[_cycle])\n",
    "        concat_df = pd.concat([concat_df, filtered_geoloc_hops[_cycle]])\n",
    "\n",
    "    G = nx.from_pandas_edgelist(\n",
    "        concat_df.loc[concat_df[\"diff_rtt\"] > 57],\n",
    "        \"near_node_id\",\n",
    "        \"far_node_id\",\n",
    "    )\n",
    "\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"near_node_asn\"].values,\n",
    "            index=concat_df[\"near_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'asn',\n",
    "    )\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"far_node_asn\"].values,\n",
    "            index=concat_df[\"far_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'asn',\n",
    "    )\n",
    "\n",
    "\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"flag_far_side_ixp\"].values,\n",
    "            index=concat_df[\"near_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'ixp_flag',\n",
    "    )\n",
    "    nx.set_node_attributes(\n",
    "        G,\n",
    "        pd.Series(\n",
    "            concat_df[\"flag_near_side_ixp\"].values,\n",
    "            index=concat_df[\"far_node_id\"]\n",
    "        ).to_dict(),\n",
    "        'ixp_flag',\n",
    "    )\n",
    "\n",
    "    t = len(G.edges())\n",
    "\n",
    "    i = 0\n",
    "    p2p = 0\n",
    "    p2c = 0\n",
    "    ixp = 0\n",
    "    tor_uknown = 0\n",
    "    unmapped = 0\n",
    "\n",
    "    for node in G.nodes():\n",
    "        for neighbor_id in G.neighbors(node):\n",
    "\n",
    "            near_asn = int(G.nodes[node][\"asn\"])\n",
    "            far_asn = int(G.nodes[neighbor_id][\"asn\"])\n",
    "\n",
    "            if (near_asn != 0) and (near_asn != 0):\n",
    "                if near_asn == far_asn:\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tor = asrel.loc[\n",
    "                        ((asrel[\"provider\"] == near_asn)\n",
    "                         & (asrel[\"customer\"] == far_asn))\n",
    "                        | ((asrel[\"customer\"] == near_asn)\n",
    "                           & (asrel[\"provider\"] == far_asn))\n",
    "                    ][\"type\"].values\n",
    "\n",
    "                    if len(tor) > 0:\n",
    "                        tor = tor[0]\n",
    "                    else:\n",
    "                        tor = 1\n",
    "\n",
    "                    if tor == -1:\n",
    "                        p2c +=1\n",
    "                    elif tor == 0:\n",
    "                        p2p += 1\n",
    "                    else:\n",
    "                        if G.nodes[node][\"ixp_flag\"] or G.nodes[neighbor_id][\"ixp_flag\"]:\n",
    "                            ixp +=1\n",
    "                        else:\n",
    "                            tor_uknown += 1\n",
    "            else:\n",
    "                unmapped += 1\n",
    "    i /= 2\n",
    "    p2p /= 2\n",
    "    p2c /= 2\n",
    "    tor_uknown /= 2\n",
    "    \n",
    "    \n",
    "    t1.append((cycle, i, p2p + p2c, unmapped, i + p2p + p2c + unmapped))\n",
    "    t2.append((cycle,  p2c, p2p, ixp, tor_uknown, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577    &5101 (0.79)    &1354 (0.21)    &17 (0.00)    &6472\\\\\n",
      "5423    &6173 (0.80)    &1538 (0.20)    &40 (0.01)    &7751\\\\\n",
      "6447    &7086 (0.79)    &1888 (0.21)    &0 (0.00)    &8974\\\\\n",
      "7616    &12406 (0.81)    &2746 (0.18)    &224 (0.01)    &15376\\\\\n",
      "8821    &14632 (0.89)    &1750 (0.11)    &2 (0.00)    &16384\\\\\n",
      "9644    &20677 (0.84)    &3876 (0.16)    &2 (0.00)    &24555\\\\\n",
      "10020    &18398 (0.85)    &3162 (0.15)    &0 (0.00)    &21560\\\\\n"
     ]
    }
   ],
   "source": [
    "for cycle, intra, inter, unmapped, t in t1:\n",
    "    print(f\"{cycle}\\\n",
    "    &{int(intra)} ({(intra / float(t)):.02f})\\\n",
    "    &{int(inter)} ({(inter / float(t)):.02f})\\\n",
    "    &{int(unmapped)} ({(unmapped / float(t)):.02f})\\\n",
    "    &{int(t)}\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577    &893 (0.13)    &461 (0.07)    &131 (0.02)    &197 (0.03)\\\\\n",
      "5423    &1044 (0.13)    &494 (0.06)    &130 (0.02)    &310 (0.04)\\\\\n",
      "6447    &1286 (0.14)    &602 (0.06)    &170 (0.02)    &211 (0.02)\\\\\n",
      "7616    &1873 (0.12)    &873 (0.06)    &187 (0.01)    &403 (0.03)\\\\\n",
      "8821    &1285 (0.08)    &465 (0.03)    &90 (0.01)    &212 (0.01)\\\\\n",
      "9644    &2961 (0.12)    &915 (0.04)    &100 (0.00)    &548 (0.02)\\\\\n",
      "10020    &2510 (0.11)    &652 (0.03)    &106 (0.00)    &637 (0.03)\\\\\n"
     ]
    }
   ],
   "source": [
    "for cycle,  p2c, p2p,  ixp, tor_uknown, t in t2:\n",
    "    print(f\"{cycle}\\\n",
    "    &{int(p2c)} ({(p2c / float(t)):.02f})\\\n",
    "    &{int(p2p)} ({(p2p / float(t)):.02f})\\\n",
    "    &{int(ixp)} ({(ixp / float(t)):.02f})\\\n",
    "    &{int(tor_uknown)} ({(tor_uknown / float(t)):.02f})\\\\\\\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lhl-edge",
   "language": "python",
   "name": ".lhl-edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
